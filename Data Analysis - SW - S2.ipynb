{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7179f0a2",
   "metadata": {},
   "source": [
    "# Análisis de la base de datos \n",
    "## Universidad de los Andes - Smurfit Westrock\n",
    "### Poyecto Intermedio de Consultoría Empresarial (PICE) 202520\n",
    "Daniel Benavides\n",
    "\n",
    "This code performs an exploratory and preparatory analysis of Smurfit Westrock’s payment data. It begins by importing and cleaning raw datasets from Excel or CSV files, addressing missing values, duplicates, and inconsistencies. The data is then transformed through normalization of numerical variables and encoding of categorical ones such as suppliers, cost centers, and expense types. Exploratory Data Analysis (EDA) is conducted to visualize payment distributions, identify outliers and temporal trends, and examine correlations among key variables. Additionally, feature engineering is applied to create new indicators that capture behavioral patterns and transaction frequency, ensuring the dataset is ready for anomaly detection models. This analysis provides preliminary insights and recommendations to guide the development of Machine Learning models and improve overall data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e75f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualizaton libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"\n",
    "import altair as alt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from matplotlib import font_manager\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f644049",
   "metadata": {},
   "source": [
    "Data downloaded as Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cada5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# DEJAR COMENTADO SI YA SE TIENE EL DATAFRAME FINAL\n",
    "# =================================================\n",
    "\n",
    "# Read and concatenate Excel files\n",
    "# df_excel = pd.concat([\n",
    "#     pd.read_excel(\"PICE BD 2025-Parte 1.xlsx\"),\n",
    "#     pd.read_excel(\"PICE BD 2025-Parte 2.xlsx\"),\n",
    "#     pd.read_excel(\"PICE BD 2025-Parte 3.xlsx\")\n",
    "# ], ignore_index=True)\n",
    "#\n",
    "# columns_to_drop = [\n",
    "#     \"Número Documento Referencia\", \"Material\", \"Número de Cuenta\",\n",
    "#     \"Acreedor\", \"Número Documento\", \"Descripción\", \"Documento Compras\",\n",
    "#     \"Pos Docum Compras\", \"Año\", \"Activo Fijo\", \"Clase de Documento\",\n",
    "#     \"Clase de Actividad\", \"Deudor\", \"Elemento PEP\", \"Orden\", \"Pedido Cliente\"\n",
    "# ]\n",
    "#\n",
    "# df_excel = (df_excel\n",
    "#             .dropna(subset=[\"Número Documento Referencia\"])\n",
    "#             .drop(columns=columns_to_drop, errors='ignore'))\n",
    "#\n",
    "# df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec0fda",
   "metadata": {},
   "source": [
    "### PICE BD 2025 JOINT CSV FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0c9a9",
   "metadata": {},
   "source": [
    "Data downloaded as CSV file (ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd947b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_csv = df_excel.to_csv(\"PICE BD 2025.csv\", index=False)\n",
    "df_csv = pd.read_csv(\"PICE BD 2025.csv\", low_memory=False)\n",
    "df_csv.info()\n",
    "\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a131c",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = df_csv.copy()\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rename(columns={\"En moneda de la sociedad\": \"Monto transado\",\n",
    "                   \"Período\": \"Mes\",\n",
    "                   \" Año \": \"Año\",\n",
    "                   \"Se ha anulado el Documento\": \"Estatus de anulación\"}, inplace=True)\n",
    "\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_series(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str)\n",
    "    s = s.str.replace(r'[^\\d\\-\\.,]', '', regex=True)\n",
    "    s = s.str.replace(',', '', regex=False)\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "# En el dataframe, existen registro anulados marcados (\"X\") y registros no anulados (NaN)\n",
    "# Transformar \"X\" a 1 y NaN a 0 en la columna \"Estatus de anulación\"\n",
    "db[\"Estatus de anulación\"] = db[\"Estatus de anulación\"].apply(lambda x: 1 if x == \"X\" else 0)\n",
    "\n",
    "# Transform date columns\n",
    "# db[\"Fecha Entrada\"] = pd.to_datetime(db[\"Fecha Entrada\"], errors='coerce')\n",
    "# db[\"Año Entrada\"] = db[\"Fecha Entrada\"].dt.year.round(0).astype('Int64')\n",
    "# db[\"Mes Entrada\"] = db[\"Fecha Entrada\"].dt.month.round(0).astype('Int64')\n",
    "# db[\"Dia Entrada\"] = db[\"Fecha Entrada\"].dt.day.round(0).astype('Int64')\n",
    "\n",
    "# db[\"Fecha Valor\"] = pd.to_datetime(db[\"Fecha Valor\"], errors='coerce', dayfirst=True)\n",
    "# db[\"Año Valor\"] = db[\"Fecha Valor\"].dt.year.round(0).astype('Int64')\n",
    "# db[\"Mes Valor\"] = db[\"Fecha Valor\"].dt.month.round(0).astype('Int64')\n",
    "# db[\"Dia Valor\"] = db[\"Fecha Valor\"].dt.day.round(0).astype('Int64')\n",
    "\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d726eb",
   "metadata": {},
   "source": [
    "### Relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"Denominación\",\"Centro de Coste\", \"Usuario\", \"Período\", \n",
    "             \"Clase\", \"Clase de Movimiento V\", \"Tipo de Documento\", \"Centro de Beneficio\", \n",
    "             \"Clase de Factura\", \"División\", \"Se ha anulado el Documento\",\n",
    "             \"Sector\"]\n",
    "\n",
    "db[variables].nunique().sort_values(ascending=False)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Variable\", \"Unique Values\"]\n",
    "for var, unique_count in db[variables].nunique().sort_values(ascending=False).items():\n",
    "    table.add_row([var, unique_count])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca78890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count percentage of missing values per column\n",
    "missing_percentage = db.isnull().mean() * 100\n",
    "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False)\n",
    "round(missing_percentage, 2)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Variable\", \"Missing Percentage\"]\n",
    "for var, perc in missing_percentage.items():\n",
    "    table.add_row([var, f\"{perc:.2f}%\"])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eebe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_impute = [ \"Sector\", \"Clase de Factura\", \"Clase de Movimiento V\",\n",
    "                        \"Centro de Coste\", \"Fecha Valor\", \"Ledger\", \"Cantidad\",\n",
    "                        \"Centro\", \"Hora\", \"Clase\", \"División\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3544382",
   "metadata": {},
   "source": [
    "# 2. Missing Data Analysis\n",
    "The missing data analysis corresponds to the reuslts provided in the python file **Missing_Data_Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Missing_Data_Analysis import comprehensive_missingness_analysis\n",
    "\n",
    "results = comprehensive_missingness_analysis(db, variables_to_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e961f",
   "metadata": {},
   "source": [
    "# 3. KNN Imputation\n",
    "The K-Nearest Neighbors (KNN) imputation method is a technique used to fill in missing values in a dataset by leveraging the K-Nearest Neighbors algorithm. This method estimates missing values based on the values of the \"k\" most similar data points (neighbors) in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ebe72c",
   "metadata": {},
   "source": [
    "# 4. Analysis of Cleaned and Imputed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa157a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of number of transactions by day and month\n",
    "# db_heatmap = db.pivot_table(index=\"Mes Entrada\", columns=\"Dia Entrada\", values=\"Monto (Millones)\", aggfunc=\"count\", fill_value=0)\n",
    "# db_heatmap.index = db_heatmap.index.astype(int)\n",
    "# db_heatmap.columns = db_heatmap.columns.astype(int)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(db_heatmap, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n",
    "# plt.title(\"Transacciones (Entrada) diarias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of number of transactions by day and month\n",
    "# db_heatmap = db.pivot_table(index=\"Mes Valor\", columns=\"Dia Valor\", values=\"Monto (Millones)\", aggfunc=\"count\", fill_value=0)\n",
    "# db_heatmap.index = db_heatmap.index.astype(int)\n",
    "# db_heatmap.columns = db_heatmap.columns.astype(int)\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(db_heatmap, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n",
    "# plt.title(\"Transacciones (Valor) diarias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc86811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.templates[\"plotly\"].layout.font.family = \"Arial\"\n",
    "pio.templates[\"plotly_white\"].layout.font.family = \"Arial\"\n",
    "pio.templates.default = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a804c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monto (millones) transado por Centro de Coste\n",
    "# db_cc_ano = db.groupby([\"Centro de Coste\"])[\"Monto (Millones)\"].sum().reset_index()\n",
    "\n",
    "# px.bar(db_cc_ano,\n",
    "       # x=\"Centro de Coste\",\n",
    "       # y=\"Monto (Millones)\",\n",
    "       # title=\"Monto (Millones) transado por Centro de Coste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7964e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio Monto (millones) transado por Centro de Coste\n",
    "# db_cc_ano = db.groupby([\"Centro de Coste\"])[\"Monto (Millones)\"].mean().reset_index()\n",
    "\n",
    "# px.bar(db_cc_ano,\n",
    "       # x=\"Centro de Coste\",\n",
    "       # y=\"Monto (Millones)\",\n",
    "       # title=\"Promedio del Monto (Millones) transado por Centro de Coste\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
